---
title: "HW4"
author: "Genavieve Middaugh"
date: "2025-02-14"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r global, echo= FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(mosaic)


```

## **Problem 1 - Iron Bank**

In this problem we are testing if the observed data is consistent with the Securities and Exchange Commissions, null hypothesis that over time security trades from Iron Bank are flagged at the same 2.4% rate as other traders.

**Null Hypothesis**: 2.4 will be our null hypothesis, this number comes from the Iron Bank employees trades that were flagged at this baseline rate of 0.024 compared to other traders.

**Test Statistic**: The number of flagged trades out of 2021 total trades which is 70/2021 = 0.03465

**Monte Carlo Simulation and P-Value**: Simulate 100000 trials where we assume each trade is 2.4% chance of being flagged. So after each trial, it will count how many trades get flagged. Below is the simulation.


```{r echo = FALSE, warning = FALSE, message = FALSE}

# given and usefull values
n_trades <- 2021
null_hypothesis <- 0.024
observed_flag <- 70 

# monte carlo sim
sim_results <- do(100000)* rbinom(1, n_trades, null_hypothesis)

p_value <- mean(sim_results$rbinom >= observed_flag)

ggplot(sim_results, aes(x = rbinom,y = ..density..)) + 
  geom_histogram(fill = "darkgreen", alpha = 0.7, bins = 25)+
  geom_vline(xintercept = observed_flag, color = "red", linetype = "dashed", size = 1) +
  labs(title = "Monte Carlo Simulated Distribution of Flagged Trades from SEC", x = "Number of Flagged Trades", y = "Probability Density")+
  theme_minimal()
p_value




```
The graph is bell shaped indicating little variation or skew, but there is a bit of inconsistency in the middle, with seemingly drastic leaps down and then upp again. The p-value we get is `r p_value`, so under the null hypothesis there is only a `r 100*(p_value)`% chance of observing 70 or more flagged trades by random chance. One would argue that this is relatively low number, it is below 0.05 and when you put it in context of the simulation, this means that the idea of being flagged 70 times is very odd, and doesn't or shouldn't happen often under a 2.4% flag rate. 

**Conclusion**: Since the p value is much smaller than 0.05 we have strong evidence to reject the null hypothesis. This value suggests that the flagged trade rate for Iron Bank employees is significantly higher than expected in the regular trading scene. 

## **Problem 2 - Health Inspections**

The local Health Department is investigating a popular local restaurant chain, Gourmet Bites, after receiving
a higher-than-usual number of health code violation reports. Here are a few key points about the situation:
• Over the last year, 1500 health inspections were conducted across various restaurants in the city, with
various branches of Gourmet Bites inspected a total of 50 times.
• Of these 50 inspections, 8 resulted in health code violations being reported.
• Typically, the Health Department’s data shows that, on average, 3% of all restaurant inspections result
in health code violations due to random issues that can occur even in well-managed establishments.
The Health Department wants to ensure that any action taken is based on solid evidence that Gourmet Bites’
rate of health code violations is significantly higher than the citywide average of 3%.
Question: Are the observed data for Gourmet Bites consistent with the Health Department’s null hypothesis
that, on average, restaurants in the city are cited for health code violations at the same 3% baseline rate?
Use a Monte Carlo simulation (with at least 100,000 simulations) to calculate a p-value under this null
hypothesis. Follow the same answer format as in the prior problem.


## **Problem 3 - Evaluating Jury Selection for Bias**



